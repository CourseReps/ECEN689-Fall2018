{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model, ensemble, tree\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit, GridSearchCV\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5097, 13)\n",
      "(1400, 12)\n"
     ]
    }
   ],
   "source": [
    "winequality_combined_training_df = pd.read_csv('ECEN689-Fall2018/Challenges/4Files/winequality-combined-training.csv')\n",
    "print(winequality_combined_training_df.shape)\n",
    "\n",
    "winequality_combined_testing_df = pd.read_csv('ECEN689-Fall2018/Challenges/4Files/winequality-combined-testing.csv')\n",
    "print(winequality_combined_testing_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = winequality_combined_training_df\n",
    "test = winequality_combined_testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = winequality_combined_training_df.iloc[:,1:12]\n",
    "y = winequality_combined_training_df.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = winequality_combined_testing_df.iloc[:,1:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_score: 0.999781992587748 validation_score: 0.984313725490196\n",
      "epoch: 2 train_score: 0.999781992587748 validation_score: 0.9882352941176471\n",
      "epoch: 3 train_score: 0.999781992587748 validation_score: 0.996078431372549\n",
      "epoch: 4 train_score: 0.999781992587748 validation_score: 0.9784313725490196\n",
      "epoch: 5 train_score: 0.999781992587748 validation_score: 0.9803921568627451\n",
      "epoch: 6 train_score: 1.0 validation_score: 0.9823529411764705\n",
      "epoch: 7 train_score: 0.999781992587748 validation_score: 0.9941176470588236\n",
      "epoch: 8 train_score: 0.999781992587748 validation_score: 0.984313725490196\n",
      "epoch: 9 train_score: 1.0 validation_score: 0.9862475442043221\n",
      "epoch: 10 train_score: 0.9997820876007845 validation_score: 0.9901574803149606\n",
      "----------\n",
      "Parameters of the classifier:  {'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': None, 'splitter': 'best'}\n",
      "----------\n",
      "Training score mean: 99.98\n",
      "Validation score mean: 98.65\n",
      "Overfitting: 1.34\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "classifier = tree.DecisionTreeClassifier()\n",
    "base_results = cross_validate(classifier, x, y, cv  = 10, return_train_score=True)\n",
    "classifier.fit(x, y)\n",
    "\n",
    "epoch=0\n",
    "for train_score,test_score in zip(base_results['train_score'], base_results['test_score']):\n",
    "        epoch +=1       \n",
    "        print(\"epoch:\",epoch,\"train_score:\",train_score, \"validation_score:\",test_score)\n",
    "print('-'*10)\n",
    "\n",
    "print('Parameters of the classifier: ', classifier.get_params())\n",
    "print('-'*10)\n",
    "print(\"Training score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \n",
    "print(\"Validation score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n",
    "oft_score = base_results['train_score'].mean() - base_results['test_score'].mean()\n",
    "print(\"Overfitting: {:.2f}\". format(oft_score*100))\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Random forest classifier to reduce the overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train_score: 0.999345977763244 validation_score: 0.9941176470588236\n",
      "epoch: 2 train_score: 0.9995639851754959 validation_score: 0.9901960784313726\n",
      "epoch: 3 train_score: 0.999345977763244 validation_score: 1.0\n",
      "epoch: 4 train_score: 0.9995639851754959 validation_score: 0.984313725490196\n",
      "epoch: 5 train_score: 0.9991279703509919 validation_score: 0.9980392156862745\n",
      "epoch: 6 train_score: 0.999345977763244 validation_score: 0.9941176470588236\n",
      "epoch: 7 train_score: 0.999345977763244 validation_score: 0.9980392156862745\n",
      "epoch: 8 train_score: 0.9991279703509919 validation_score: 0.9980392156862745\n",
      "epoch: 9 train_score: 0.999128160418483 validation_score: 0.9921414538310412\n",
      "epoch: 10 train_score: 0.999128350403138 validation_score: 0.9921259842519685\n",
      "----------\n",
      "Parameters of the classifier:  {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "----------\n",
      "Training score mean: 99.93\n",
      "Validation score mean: 99.41\n",
      "Overfitting: 0.52\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "classifier = ensemble.RandomForestClassifier()\n",
    "base_results = cross_validate(classifier, x, y, cv  = 10, return_train_score=True)\n",
    "classifier.fit(x, y)\n",
    "\n",
    "epoch=0\n",
    "for train_score,test_score in zip(base_results['train_score'], base_results['test_score']):\n",
    "        epoch +=1       \n",
    "        print(\"epoch:\",epoch,\"train_score:\",train_score, \"validation_score:\",test_score)\n",
    "print('-'*10)\n",
    "\n",
    "print('Parameters of the classifier: ', classifier.get_params())\n",
    "print('-'*10)\n",
    "print(\"Training score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \n",
    "print(\"Validation score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n",
    "oft_score = base_results['train_score'].mean() - base_results['test_score'].mean()\n",
    "print(\"Overfitting: {:.2f}\". format(oft_score*100))\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(x_test)\n",
    "df = pd.DataFrame()\n",
    "df['Id'] = test['Id']\n",
    "df['type']=predicted\n",
    "df.to_csv('winequality_combined_solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for random forest using grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ensemble.RandomForestClassifier()\n",
    "base_results = cross_validate(classifier, x, y, cv  = None, return_train_score=True)\n",
    "classifier.fit(x, y)\n",
    "\n",
    "epoch=0\n",
    "for train_score,test_score in zip(base_results['train_score'], base_results['test_score']):\n",
    "        epoch +=1       \n",
    "        print(\"epoch:\",epoch,\"train_score:\",train_score, \"validation_score:\",test_score)\n",
    "print('-'*10)\n",
    "\n",
    "print('BEFORE Tuning Parameters: ', classifier.get_params())\n",
    "print('-'*10)\n",
    "print(\"BEFORE Tuning Training score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \n",
    "print(\"BEFORE Tuning validation score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n",
    "oft_score = base_results['train_score'].mean() - base_results['test_score'].mean()\n",
    "print(\"Overfitting before tuning: {:.2f}\". format(oft_score*100))\n",
    "print('-'*10)\n",
    "\n",
    "param_grid = {'n_estimators': [50, 150, 200],\n",
    "              'criterion': ['gini','entropy'],  #scoring methodology; two supported formulas for calculating information gain - default is gini\n",
    "              'max_depth': [2,4,6,None], #max depth tree can grow; default is none\n",
    "              'min_samples_split': [5,7,10], #minimum subset size BEFORE new split (fraction is % of total); default is 2\n",
    "              #'min_samples_leaf': [1,3,5], #minimum subset size AFTER new split split (fraction is % of total); default is 1\n",
    "              'max_features': [2,3,'auto'], #max features to consider when performing split; default none or all\n",
    "              'random_state': [0] #seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\n",
    "             }\n",
    "\n",
    "tune_model = GridSearchCV(ensemble.RandomForestClassifier(), param_grid=param_grid, scoring = 'accuracy', cv = None, return_train_score=True)\n",
    "tune_model.fit(x, y)\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"epoch:\",i,\"train_score:\",tune_model.cv_results_['split'+str(i)+'_train_score'][tune_model.best_index_],\n",
    "    \"test_score:\",tune_model.cv_results_['split'+str(i)+'_test_score'][tune_model.best_index_])\n",
    "\n",
    "print('-'*10)    \n",
    "\n",
    "\n",
    "print('AFTER Tuning Parameters: ', tune_model.best_params_)\n",
    "print('-'*10)\n",
    "print(\"AFTER Tuning Training score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100))\n",
    "print(\"AFTER Tuning validation score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "oft_score = tune_model.cv_results_['mean_train_score'][tune_model.best_index_] - tune_model.cv_results_['mean_test_score'][tune_model.best_index_]\n",
    "print(\"Overfitting after tuning: {:.2f}\". format(oft_score*100))\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now using this random forest model trained on combined dataset with high training accuracy, let us predict the red wine dataset and check the confuion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199, 13)\n",
      "(400, 12)\n"
     ]
    }
   ],
   "source": [
    "red_train = pd.read_csv('ECEN689-Fall2018/Challenges/4Files/winequality-red-training.csv')\n",
    "print(red_train.shape)\n",
    "\n",
    "red_test = pd.read_csv('ECEN689-Fall2018/Challenges/4Files/winequality-red-testing.csv')\n",
    "print(red_test.shape)\n",
    "\n",
    "red_x_train = red_train.iloc[:,1:12]\n",
    "red_y_train = np.ones(1199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0],\n",
       "       [   2, 1197]], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = classifier.predict(red_x_train)\n",
    "confusion_matrix(red_y_train, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we can observe that out of 1199 red wine data points, the model trained on the combined dataset is predicting 1197 data points as red wine. So, in this context the model can be reused and higher the model calssification accuracy, better the advantage of reusability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
