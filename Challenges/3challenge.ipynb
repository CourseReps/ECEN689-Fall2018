{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3\n",
    "\n",
    "## Reading Materials\n",
    "\n",
    "\n",
    "### [Kaggle Tutorials](https://www.kaggle.com/learn/overview)\n",
    "Due: October 2, 2018\n",
    "~~Due: September 27, 2018~~\n",
    "\n",
    " * __Complete__ [Data Visualisation course](https://www.kaggle.com/learn/data-visualisation), if needed\n",
    "\n",
    "\n",
    "## Activity 3: World Bank Data\n",
    "Due: October 2, 2018\n",
    "~~Due: September 27, 2018~~\n",
    "\n",
    "Activity 3 is based on the [World Bank Data](https://www.kaggle.com/gemartin/world-bank-data-1960-to-2016), which aggregates the population of various countries, along with fertility rate and life expectancy, from 1960 to 2016.\n",
    "The goal of this activity is to explore a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and limit the fragility of a statistical model.\n",
    "Relevant topics for this challenge include the following sections.\n",
    " * Linear Regression (Section 9.2)\n",
    " * Regularized Loss Minimization (Section 13.1)\n",
    " * Stable Rules Do Not Overfit (Section 13.2)\n",
    "\n",
    "\n",
    "### Least Squares\n",
    "\n",
    "The method of least squares is a standard approach in regression analysis to approximate the solution of overdetermined systems.\n",
    "This technique is used extensively in the context of data fitting; the best fit in the least-squares sense minimizes the sum of squared residuals.\n",
    "In the current context, a regularized version to the least squares solution is highly desirable.\n",
    "Ridge regression, or Tikhonov regularization, adds the constraint that the $L_2$-norm of the parameter vector remains no greater than a given value.\n",
    "An alternative regularized version of least squares is Lasso (least absolute shrinkage and selection operator), which uses the constraint that the $L_1$-norm of the parameter vector be no greater than a given value.\n",
    "The latter constraint, which we will focus on, favors sparsity in the solution.\n",
    "\n",
    "\n",
    "### Data\n",
    "\n",
    "As mentioned above, the data we are using is based on the [World Bank Data](https://www.kaggle.com/gemartin/world-bank-data-1960-to-2016).\n",
    "Specifically, we are using a cleaned up version of `country_population.csv` where incomplete rows have been removed and extraneous columns have been deleted.\n",
    "The intent is to use year 1960 to 1999 to train a least squares model and, subsequently, explore its prediction power for year 2001 to 2016.\n",
    "For a given country, the solution should be a population estimate based on a linear combination of (at most) five other countries.\n",
    "Mathematically, the population of country $C_0$ is estimated based on the population of five other countries,\n",
    "\\begin{equation*}\n",
    "\\hat{C}_0(\\text{year}) = \\sum_i \\alpha_i C_i(\\text{year})\n",
    "\\end{equation*}\n",
    "subject to $\\| \\boldsymbol{\\alpha} \\|_0 \\leq 5$.\n",
    "For every country, the parameters $\\boldsymbol{\\alpha}$ must be derived based on populations from 1960 to 1999.\n",
    "\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "The evaluation criterion is the average sum of squared residuals for populations from 2000 to 2016.\n",
    "\n",
    "\n",
    "### File Descriptions\n",
    "\n",
    " * `population_training.csv` – the training data\n",
    " * `population_training_kaggle.csv` – the training data in Kaggle format  (40 x 259)\n",
    " * `population_testing.csv` – the test data\n",
    " * `population_testing_kaggle.csv` – the test data in Kaggle format (17 x 259)\n",
    " * `population_sample_kaggle.csv` – A sample Kaggle solution (17 x 259)\n",
    " * `population_parameters.csv` – A sample parameters file (259 x 259)\n",
    "\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "User submissions are evaluated by comparing their submission CSV to the ground truth solution CSV with respect to Least Squares.\n",
    "\n",
    "* __Kaggle__: Every team should enter the Kaggle competition and submit a prediction file for years 2000 to 2016 in the Kaggle format, as specified in `population_sample_kaggle.csv`.\n",
    "* __GitHub__: Every team should commit and push two files:\n",
    "  * A pediction file for years 2000 to 2016 (17 x 259)\n",
    "  * A parameter file one column per country (259 x 259)\n",
    "  * Jupyter notebook code or Python code\n",
    "\n",
    "Every column in `population_parameters.csv` should be 5-sparse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "population_training_df = pd.read_csv('3Files/population_training.csv', encoding='cp1252').dropna(axis=0)\n",
    "population_testing_df = pd.read_csv('3Files/population_testing.csv', encoding='cp1252').dropna(axis=0)\n",
    "print(population_training_df.shape)\n",
    "print(population_testing_df.shape)\n",
    "population_training_df.drop(['Country Name'], axis=1, inplace=True)\n",
    "population_testing_df.drop(['Country Name'], axis=1, inplace=True)\n",
    "\n",
    "population_training_matrix = population_training_df.values\n",
    "population_testing_matrix = population_testing_df.values\n",
    "print(population_training_matrix.shape)\n",
    "print(population_testing_matrix.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can use the `sklearn` package to perform ridge regression and lasso.\n",
    "The main functions in this package that we care about are `Ridge()`, which can be used to fit ridge regression models, and `Lasso()` which will fit lasso models.\n",
    "\n",
    "The `Ridge()` function has an `alpha` argument that is employed to tune the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(10,-2,5)*0.5\n",
    "alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associated with each `alpha` value is a vector of ridge regression coefficients, stored in a matrix `coefs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(normalize = True)\n",
    "coefs = []\n",
    "\n",
    "print(population_training_matrix.shape)\n",
    "print(population_training_vector.shape)\n",
    "\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha = a)\n",
    "    ridge.fit(population_matrix.transpose(), population_vector)\n",
    "    coefs.append(ridge.coef_)\n",
    "    \n",
    "np.shape(coefs)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
