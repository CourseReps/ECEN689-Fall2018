{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mini Project 6 - MNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "BYhCBK_Prai9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mini Project 6\n",
        "\n",
        "Exploring Neural Networks and Learning Google Collab\n",
        "\n",
        "Idea: Use random-generated noise (NaN) entries as well to see if it 1. improves the results and 2. Improves the intuitive 'picture' from the visualized weights"
      ]
    },
    {
      "metadata": {
        "id": "qyMEuO5srM7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# imports and set-up for session\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a2qeu1JrtsPn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Kaggle Setup and Load Files from API\n",
        "\n",
        "Commented out so full run does not re-load"
      ]
    },
    {
      "metadata": {
        "id": "KU-G8qHQtpfl",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "ca3ad806-6c0a-450e-feca-c206e8e7a01f"
      },
      "cell_type": "code",
      "source": [
        "# Upload API key from local drive\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Kaggle API install\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# Load the data\n",
        "!kaggle competitions download -c mnist-digit-classification-2\n",
        "!mkdir mnist\n",
        "!unzip mnist_train.csv.zip\n",
        "!unzip mnist_test.csv.zip\n",
        "!mv mnist_train.csv mnist \n",
        "!mv mnist_test.csv mnist \n",
        "!mv mnist_sample.csv mnist\n",
        "!rm mnist_train.csv.zip\n",
        "!rm mnist_test.csv.zip\n",
        "!ls mnist"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-52d30864-7494-4705-9976-4d2aab24607d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-52d30864-7494-4705-9976-4d2aab24607d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading mnist_sample.csv to /content\n",
            "  0% 0.00/77.1k [00:00<?, ?B/s]\n",
            "100% 77.1k/77.1k [00:00<00:00, 27.1MB/s]\n",
            "Downloading mnist_test.csv.zip to /content\n",
            "  0% 0.00/2.12M [00:00<?, ?B/s]\n",
            "100% 2.12M/2.12M [00:00<00:00, 113MB/s]\n",
            "Downloading mnist_train.csv.zip to /content\n",
            " 78% 10.0M/12.8M [00:00<00:00, 19.5MB/s]\n",
            "100% 12.8M/12.8M [00:00<00:00, 29.5MB/s]\n",
            "Archive:  mnist_train.csv.zip\n",
            "  inflating: mnist_train.csv         \n",
            "Archive:  mnist_test.csv.zip\n",
            "  inflating: mnist_test.csv          \n",
            "mnist_sample.csv  mnist_test.csv  mnist_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-GGZGfTaxo54",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Training Data Set\n",
        "\n",
        "Original first"
      ]
    },
    {
      "metadata": {
        "id": "dYad10u919Sw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b5dd311-f52b-41c3-baa3-c2659fdbd30f"
      },
      "cell_type": "code",
      "source": [
        "training = pd.read_csv('mnist/mnist_train.csv', index_col=0)\n",
        "train_X = training.drop('Category',axis=1).values\n",
        "train_y = training['Category'].values\n",
        "print(training.shape, train_X.shape, train_y.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 785) (60000, 784) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2DOuQaMvBcoe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# conduct PCA\n",
        "pca = PCA()\n",
        "pca_X = pca.fit_transform(train_X)\n",
        "components = len(pca.explained_variance_ratio_[pca.explained_variance_ratio_> 1e-20])\n",
        "\n",
        "pca_X = pca_X[:,:components]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-40wOa9B3uEx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create random, unrelated portion. Category NaN (label is 10).\n",
        "Hope is that training with this will improve generalization by acting as a sort of regularization"
      ]
    },
    {
      "metadata": {
        "id": "oraFRP6D2xl8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_samples = pd.value_counts(training['Category'].values).max()\n",
        "rand_X = np.random.randint(0, 256, (num_samples, train_X.shape[1]))\n",
        "rand_y = np.full((num_samples,), 10) # label 10 means 'not a digit'\n",
        "\n",
        "full_X = np.concatenate((train_X,rand_X))\n",
        "full_y = np.concatenate((train_y,rand_y))\n",
        "ordering = np.random.shuffle(np.arange(0, full_y.shape[0]))\n",
        "full_X = full_X[ordering][0]\n",
        "full_y = full_y[ordering][0]\n",
        "\n",
        "pca_full_X = pca.transform(full_X)[:,:components]\n",
        "\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dedAZ83sqi2y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create one plain and one noised for convolutional network"
      ]
    },
    {
      "metadata": {
        "id": "L9AQVtV0qiBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reshape and normalize (remember to do the same to the test set)\n",
        "train_X_2D = train_X.reshape((train_X.shape[0], 28, 28, 1)) / 255.0\n",
        "full_X_2D = full_X.reshape((full_X.shape[0], 28, 28, 1)) / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KO2rAVeZ6wjX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Tensorflow Networks\n",
        "\n",
        "Build the actual sessions which will be trained and validated. The first without noise input, the second with."
      ]
    },
    {
      "metadata": {
        "id": "iuHKddmi6809",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_model_basic():\n",
        "  model_basic = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(640, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(320, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(160, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(80, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(40, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(20, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "  ])\n",
        "  model_basic.compile(\n",
        "    optimizer=tf.keras.optimizers.Adadelta(),  # Adam(lr=0.0001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  return model_basic\n",
        "\n",
        "def make_model_2D_basic():\n",
        "  model_basic = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "  ])\n",
        "  model_basic.compile(\n",
        "    optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0),  # Adam(lr=0.0001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  return model_basic\n",
        "\n",
        "def make_model_noised():\n",
        "  model_noised = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(1000, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(704, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(352, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(176, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(88, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(44, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(22, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(11, activation=tf.nn.softmax)\n",
        "  ])\n",
        "  model_noised.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "  return model_noised\n",
        "\n",
        "def make_model_2D_noised():\n",
        "  model_noised = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu', input_shape=(28,28,1)),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(11, activation=tf.nn.softmax)\n",
        "  ])\n",
        "  model_noised.compile(\n",
        "    optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0),  # Adam(lr=0.0001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "  return model_noised"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "URlVdgYF2oxh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# helpers for fitting\n",
        "\n",
        "# annealer\n",
        "lr_annealing = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_acc', patience=3, factor=0.5, min_lr=0.00001)\n",
        "\n",
        "# date generator\n",
        "def make_datagen(data):\n",
        "    dg = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        zca_whitening=False,\n",
        "        rotation_range=10,\n",
        "        zoom_range = 0.1,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=False,\n",
        "        vertical_flip=False\n",
        "    )\n",
        "#     dg.fit(data)\n",
        "    return dg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p2GbVGHaEhqH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cross-Validate the Networks\n",
        "\n",
        "Cross-validation function"
      ]
    },
    {
      "metadata": {
        "id": "8blxxciUVcML",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classify_cross_val_score(\n",
        "  estimator,\n",
        "  X,\n",
        "  y,\n",
        "  cv=4,\n",
        "  scoring=None,\n",
        "  fit_params={},\n",
        "  convert=lambda x:x\n",
        "):\n",
        "  score = 0\n",
        "  for train, test in StratifiedShuffleSplit(cv).split(X,y):\n",
        "    model = estimator()\n",
        "    model.fit(X[train], y[train], **fit_params)\n",
        "    s_part = accuracy_score(y[test], convert(model.predict(X[test])))\n",
        "    print(s_part)\n",
        "    score += s_part/cv\n",
        "  return score\n",
        "\n",
        "def classify_cross_val_score_generator(\n",
        "  estimator,\n",
        "  X,\n",
        "  y,\n",
        "  datagen,\n",
        "  cv=4,\n",
        "  scoring=None,\n",
        "  fit_params={},\n",
        "  convert=lambda x:x,\n",
        "  batch_size=86\n",
        "):\n",
        "  score = 0\n",
        "  for train, test in StratifiedShuffleSplit(cv).split(X,y):\n",
        "    model = estimator()\n",
        "    datagen.fit(X[train])\n",
        "    model.fit_generator(\n",
        "        datagen.flow(X[train], y[train], batch_size=batch_size), \n",
        "        validation_data=(X[test], y[test]),\n",
        "        steps_per_epoch=train.shape[0] // batch_size,\n",
        "        **fit_params\n",
        "    )\n",
        "    s_part = accuracy_score(y[test], convert(model.predict(X[test])))\n",
        "    print(s_part)\n",
        "    score += s_part/cv\n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iRZbFuVwyxTb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "basic fully-connected"
      ]
    },
    {
      "metadata": {
        "id": "LYZoYu4pEcEl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 5:  0.95879\n",
        "# 10: 0.99254\n",
        "# 20: 0.97529\n",
        "for e in [20]:\n",
        "  score_basic = classify_cross_val_score(\n",
        "      make_model_basic,\n",
        "      train_X,  # pca_X,\n",
        "      train_y,\n",
        "      cv=4,\n",
        "      fit_params={'epochs':e},\n",
        "      convert = lambda x:np.argmax(x, axis=1)\n",
        "  )\n",
        "  print(score_basic)\n",
        "\n",
        "# model_basic.fit(train_X, train_y, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I0nN13_WFqlN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "noised fully-connected"
      ]
    },
    {
      "metadata": {
        "id": "PqBhiEqWFrzm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for e in [10]:\n",
        "  score_noised = classify_cross_val_score(\n",
        "      make_model_noised,\n",
        "      full_X,  # pca_full_X,\n",
        "      full_y,\n",
        "      cv=4,\n",
        "      fit_params={'epochs':e},\n",
        "      convert = lambda x:np.argmax(x, axis=1)\n",
        "  )\n",
        "  print(score_noised)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AsxNoj0_y3-H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "basic CNN"
      ]
    },
    {
      "metadata": {
        "id": "Oien4E3Ry-Bk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for e in [20]:\n",
        "  score_basic = classify_cross_val_score_generator(\n",
        "      make_model_2D_basic,\n",
        "      train_X_2D,  # pca_X,\n",
        "      train_y,\n",
        "      make_datagen(train_X_2D),\n",
        "      cv=10,\n",
        "      fit_params={\n",
        "          'epochs':e,\n",
        "          'callbacks':[lr_annealing],\n",
        "      },\n",
        "      convert = lambda x:np.argmax(x, axis=1)\n",
        "  )\n",
        "  print(score_basic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a_2D2rhZy34T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "NaN-added CNN"
      ]
    },
    {
      "metadata": {
        "id": "WY0F1GUzrTh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        },
        "outputId": "38e66f7a-bc88-4abb-a2ef-a19d4dff7ca0"
      },
      "cell_type": "code",
      "source": [
        "for e in [20]:\n",
        "  score_basic = classify_cross_val_score_generator(\n",
        "      make_model_2D_noised,\n",
        "      full_X_2D,  # pca_X,\n",
        "      full_y,\n",
        "      make_datagen(train_X_2D),\n",
        "      cv=10,\n",
        "      fit_params={\n",
        "          'epochs':e,\n",
        "          'callbacks':[lr_annealing],\n",
        "      },\n",
        "      convert = lambda x:np.argmax(x, axis=1),\n",
        "      batch_size = 128\n",
        "  )\n",
        "  print(score_basic)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 11/469 [..............................] - ETA: 8:45 - loss: 2.3397 - acc: 0.1449"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1a144573e2e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       },\n\u001b[1;32m     12\u001b[0m       \u001b[0mconvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   )\n\u001b[1;32m     15\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_basic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-1690ac970c97>\u001b[0m in \u001b[0;36mclassify_cross_val_score_generator\u001b[0;34m(estimator, X, y, datagen, cv, scoring, fit_params, convert, batch_size)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m     \u001b[0ms_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 176\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "c5ejE3CWyFlS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Final Classification\n",
        "\n",
        "Train, predict, and save\n",
        "\n",
        "The CNN with NaN entries performed best in cross-validation; train with that set-up.\n",
        "Since NaN entries are known not to be in the actual test set, eliminate from predictions"
      ]
    },
    {
      "metadata": {
        "id": "WQuYTc5_yC1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1b14cbca-c4ca-45c8-b086-568e9a1d4a1d"
      },
      "cell_type": "code",
      "source": [
        "test_X= pd.read_csv('mnist/mnist_test.csv', index_col=0).values\n",
        "test_pred = pd.read_csv('mnist/mnist_sample.csv', index_col=0)\n",
        "print(test_X.shape, test_pred.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784) (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8odYlwSncXb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1137
        },
        "outputId": "d36eefba-d773-4a41-8b18-e0869cb1527e"
      },
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model = make_model_2D_noised()\n",
        "datagen = make_datagen(full_X_2D)\n",
        "datagen.fit(full_X_2D)\n",
        "lr_annealing = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='acc', patience=3, factor=0.5, min_lr=0.00001)\n",
        "\n",
        "model.fit_generator(\n",
        "    datagen.flow(train_X_2D, train_y, batch_size=128),\n",
        "    epochs=30,\n",
        "    callbacks=[lr_annealing],\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "469/469 [==============================] - 497s 1s/step - loss: 0.4217 - acc: 0.8613\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 496s 1s/step - loss: 0.1009 - acc: 0.9703\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 497s 1s/step - loss: 0.0736 - acc: 0.9787\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 490s 1s/step - loss: 0.0631 - acc: 0.9822\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 491s 1s/step - loss: 0.0560 - acc: 0.9844\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 491s 1s/step - loss: 0.0515 - acc: 0.9853\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 487s 1s/step - loss: 0.0508 - acc: 0.9863\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 490s 1s/step - loss: 0.0513 - acc: 0.9861\n",
            "Epoch 9/30\n",
            "469/469 [==============================] - 488s 1s/step - loss: 0.0517 - acc: 0.9858\n",
            "Epoch 10/30\n",
            "469/469 [==============================] - 490s 1s/step - loss: 0.0514 - acc: 0.9868\n",
            "Epoch 11/30\n",
            "469/469 [==============================] - 490s 1s/step - loss: 0.0512 - acc: 0.9864\n",
            "Epoch 12/30\n",
            "469/469 [==============================] - 490s 1s/step - loss: 0.0518 - acc: 0.9870\n",
            "Epoch 13/30\n",
            "469/469 [==============================] - 491s 1s/step - loss: 0.0537 - acc: 0.9870\n",
            "Epoch 14/30\n",
            "469/469 [==============================] - 491s 1s/step - loss: 0.0539 - acc: 0.9860\n",
            "Epoch 15/30\n",
            "469/469 [==============================] - 493s 1s/step - loss: 0.0548 - acc: 0.9860\n",
            "Epoch 16/30\n",
            "469/469 [==============================] - 494s 1s/step - loss: 0.0426 - acc: 0.9895\n",
            "Epoch 17/30\n",
            "469/469 [==============================] - 497s 1s/step - loss: 0.0375 - acc: 0.9898\n",
            "Epoch 18/30\n",
            "469/469 [==============================] - 496s 1s/step - loss: 0.0399 - acc: 0.9903\n",
            "Epoch 19/30\n",
            "469/469 [==============================] - 495s 1s/step - loss: 0.0389 - acc: 0.9903\n",
            "Epoch 20/30\n",
            "469/469 [==============================] - 496s 1s/step - loss: 0.0376 - acc: 0.9902\n",
            "Epoch 21/30\n",
            "469/469 [==============================] - 492s 1s/step - loss: 0.0413 - acc: 0.9898\n",
            "Epoch 22/30\n",
            "469/469 [==============================] - 491s 1s/step - loss: 0.0320 - acc: 0.9920\n",
            "Epoch 23/30\n",
            "469/469 [==============================] - 488s 1s/step - loss: 0.0307 - acc: 0.9918\n",
            "Epoch 24/30\n",
            "469/469 [==============================] - 489s 1s/step - loss: 0.0318 - acc: 0.9916\n",
            "Epoch 25/30\n",
            "469/469 [==============================] - 498s 1s/step - loss: 0.0320 - acc: 0.9917\n",
            "Epoch 26/30\n",
            "469/469 [==============================] - 494s 1s/step - loss: 0.0303 - acc: 0.9921\n",
            "Epoch 27/30\n",
            "469/469 [==============================] - 495s 1s/step - loss: 0.0291 - acc: 0.9927\n",
            "Epoch 28/30\n",
            "469/469 [==============================] - 493s 1s/step - loss: 0.0289 - acc: 0.9923\n",
            "Epoch 29/30\n",
            "469/469 [==============================] - 492s 1s/step - loss: 0.0281 - acc: 0.9927\n",
            "Epoch 30/30\n",
            "469/469 [==============================] - 491s 1s/step - loss: 0.0283 - acc: 0.9925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb91653fe10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "Id_s4LkIzioT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1211
        },
        "outputId": "798ff828-c89e-4aff-8f61-cd137989604d"
      },
      "cell_type": "code",
      "source": [
        "pred = np.argmax(np.array(model.predict(test_X.reshape(-1,28,28,1)/255))[:,:10], axis=1)\n",
        "test_pred['Category'] = pred\n",
        "print(test_pred.head(100))\n",
        "test_pred.to_csv('mnist_submission.csv', index=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Category\n",
            "Id           \n",
            "1           7\n",
            "2           2\n",
            "3           1\n",
            "4           0\n",
            "5           4\n",
            "6           1\n",
            "7           4\n",
            "8           9\n",
            "9           5\n",
            "10          9\n",
            "11          0\n",
            "12          6\n",
            "13          9\n",
            "14          0\n",
            "15          1\n",
            "16          5\n",
            "17          9\n",
            "18          7\n",
            "19          3\n",
            "20          4\n",
            "21          9\n",
            "22          6\n",
            "23          6\n",
            "24          5\n",
            "25          4\n",
            "26          0\n",
            "27          7\n",
            "28          4\n",
            "29          0\n",
            "30          1\n",
            "..        ...\n",
            "71          7\n",
            "72          0\n",
            "73          2\n",
            "74          9\n",
            "75          1\n",
            "76          7\n",
            "77          3\n",
            "78          2\n",
            "79          9\n",
            "80          7\n",
            "81          7\n",
            "82          6\n",
            "83          2\n",
            "84          7\n",
            "85          8\n",
            "86          4\n",
            "87          7\n",
            "88          3\n",
            "89          6\n",
            "90          1\n",
            "91          3\n",
            "92          6\n",
            "93          9\n",
            "94          3\n",
            "95          1\n",
            "96          4\n",
            "97          1\n",
            "98          7\n",
            "99          6\n",
            "100         9\n",
            "\n",
            "[100 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rwVBSppLxivW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "58840aec-50db-4bf1-b780-5e60846ce319"
      },
      "cell_type": "code",
      "source": [
        "# download prediction to submit\n",
        "!ls\n",
        "files.download('mnist_submission.csv')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist  mnist_submission.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}