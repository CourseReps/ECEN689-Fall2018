{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "2HpW7yqKcuLK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S08wI0CyZ2uM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1tkmYIvKaCpY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cnn_model_fn(features, labels, mode):\n",
        "  \n",
        "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
        "  \n",
        "  conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
        "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
        "  \n",
        "  conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
        "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
        "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
        "  \n",
        "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
        "  dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
        "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
        "  \n",
        "  predictions = {\"classes\": tf.argmax(input=logits, axis=1), \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")}\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "  \n",
        "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
        "    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
        "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "  \n",
        "  eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
        "  return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GhHMkD8Icn_y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def one_hot_fn(values):\n",
        "  \n",
        "  ret = []\n",
        "  for value in values:\n",
        "    tmp = np.zeros(10)\n",
        "    tmp[value] = 1\n",
        "    ret.append(tmp)\n",
        "  return (np.array(ret,dtype=int))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSWPuIj0J0YP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def threshold_fn(X):\n",
        "  for i in len(X):\n",
        "    for j in len(X[i]):\n",
        "      if X[i][j] >= 100:\n",
        "        X[i][j] = 1\n",
        "      else:\n",
        "        X[i][j] = 0\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mJZTyUNbd5Nk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(io.StringIO(uploaded['mnist_train.csv'].decode('utf-8')))\n",
        "\n",
        "train_labels = pd.DataFrame()\n",
        "train_labels['Category'] = train['Category']\n",
        "train_values = train.drop(['Id', 'Category'], axis=1)\n",
        "\n",
        "train_data = np.array(train_values.values.tolist(), dtype=float)\n",
        "train_lab = np.array(train_labels.values.tolist(), dtype=int)\n",
        "\n",
        "train_data = threshold_fn(train_data)\n",
        "train_labe = one_hot_fn(train_lab)\n",
        "\n",
        "test1 = pd.read_csv(io.StringIO(uploaded['mnist_test.csv'].decode('utf-8')))\n",
        "test_df = test1.drop(['Id'], axis=1)\n",
        "test_values1 = np.array(test_df.values.tolist(), dtype=float)\n",
        "test_values1 = threshold_fn(test_values1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gDuunFiMfEJj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
        "\n",
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": train_data}, y=train_lab, batch_size=100, num_epochs=None, shuffle=True)\n",
        "\n",
        "mnist_classifier.train(input_fn=train_input_fn, steps=20000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YGCaUb2MOKo7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": test_values1}, shuffle=False)\n",
        "preds = mnist_classifier.predict(pred_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cjYo_0IojrHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for i in range(10000):\n",
        "  predictions.append(next(preds)['classes'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3BmBdEe6mLV0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full_mat = []\n",
        "for i in range(len(predictions)):\n",
        "  full_mat.append([i+1, predictions[i]])\n",
        "\n",
        "labels = ['Id', 'Category']\n",
        "new_df = pd.DataFrame.from_records(full_mat, columns=labels)\n",
        "new_df.to_csv('predictions_cnn.csv',index=False)\n",
        "#print(new_df.head(5))\n",
        "files.download('predictions_cnn.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}