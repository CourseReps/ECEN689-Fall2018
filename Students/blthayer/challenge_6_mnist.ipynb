{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "challenge_6_mnist.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "06yWs2QCXMue",
        "colab_type": "code",
        "outputId": "69876829-1890-4dc9-cc1b-84b3e41bf996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# https://medium.com/@move37timm/using-kaggle-api-for-google-colaboratory-d18645f93648\n",
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth, files\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "# Test if we have a GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SDLyPxRxPB7S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download data from Kaggle."
      ]
    },
    {
      "metadata": {
        "id": "MD6QEezAst3O",
        "colab_type": "code",
        "outputId": "d7c0f30d-fbbd-4955-89d5-a9075a0012fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "# Get data from kaggle\n",
        "# https://medium.com/@move37timm/using-kaggle-api-for-google-colaboratory-d18645f93648\n",
        "!pip install kaggle\n",
        "\n",
        "# Copy + pasted from medium article:\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "# Had to change this from /content to /root.\n",
        "filename = \"/root/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)\n",
        "\n",
        "# API call from Kaggle\n",
        "!kaggle competitions download -c mnist-digit-classification-2\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/9b/ac57e15fbb239c6793c8d0b7dfd1a4c4a025eaa9f791b5388a7afb515aed/kaggle-1.5.0.tar.gz (53kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.10.15)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Collecting python-slugify (from kaggle)\n",
            "  Downloading https://files.pythonhosted.org/packages/00/ad/c778a6df614b6217c30fe80045b365bfa08b5dd3cb02e8b37a6d25126781/python-slugify-1.2.6.tar.gz\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Collecting Unidecode>=0.04.16 (from python-slugify->kaggle)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/ef/67085e30e8bbcdd76e2f0a4ad8151c13a2c5bce77c85f8cad6e1f16fb141/Unidecode-1.0.22-py2.py3-none-any.whl (235kB)\n",
            "\u001b[K    100% |████████████████████████████████| 235kB 3.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle, python-slugify\n",
            "  Running setup.py bdist_wheel for kaggle ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/8b/21/3b/a0076243c6ae12a6215b2da515fe06b539aee7217b406e510e\n",
            "  Running setup.py bdist_wheel for python-slugify ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e3/65/da/2045deea3098ed7471eca0e2460cfbd3fdfe8c1d6fa6fcac92\n",
            "Successfully built kaggle python-slugify\n",
            "Installing collected packages: Unidecode, python-slugify, kaggle\n",
            "Successfully installed Unidecode-1.0.22 kaggle-1.5.0 python-slugify-1.2.6\n",
            "Download 100%.\n",
            "Downloading mnist_sample.csv to /content\n",
            "  0% 0.00/77.1k [00:00<?, ?B/s]\n",
            "100% 77.1k/77.1k [00:00<00:00, 34.4MB/s]\n",
            "Downloading mnist_test.csv.zip to /content\n",
            "  0% 0.00/2.12M [00:00<?, ?B/s]\n",
            "100% 2.12M/2.12M [00:00<00:00, 51.6MB/s]\n",
            "Downloading mnist_train.csv.zip to /content\n",
            " 78% 10.0M/12.8M [00:00<00:00, 12.3MB/s]\n",
            "100% 12.8M/12.8M [00:00<00:00, 17.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nt-UjLfrPHbS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read MNIST training data, split for training/testing"
      ]
    },
    {
      "metadata": {
        "id": "JZQHvAErOjM0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SEED=5387\n",
        "# Grab data.\n",
        "df_train = pd.read_csv('/content/mnist_train.csv.zip', compression='zip',\n",
        "                      index_col=0)\n",
        "df_test = pd.read_csv('/content/mnist_test.csv.zip', compression='zip',\n",
        "                      index_col=0)\n",
        "df_sample = pd.read_csv('/content/mnist_sample.csv', index_col=0)\n",
        "#print('Training data:')\n",
        "#print(df_train.head(10))\n",
        "#print(df_train.describe())\n",
        "#print('Testing data:')\n",
        "#print(df_test.head(3))\n",
        "x = df_train.drop(['Category'], axis=1).values\n",
        "\n",
        "# Normalize x.\n",
        "x = x / 255.0\n",
        "df_test = df_test/255.0\n",
        "\n",
        "# Reshape for convolutional network. Convolutional network stuff from:\n",
        "# https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "#np.reshape(x, (x.shape[0], 28, 28))\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_conv = np.reshape(x, (x.shape[0], 1, img_rows, img_cols))\n",
        "    x_final = np.reshape(df_test.values, (df_test.shape[0], 1, img_rows, img_cols))\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_conv = np.reshape(x, (x.shape[0], img_rows, img_cols, 1))\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "    x_final = np.reshape(df_test.values, (df_test.shape[0], img_rows, img_cols, 1))\n",
        "y = df_train['Category'].values\n",
        "# print(x_train.describe())\n",
        "\n",
        "# Split data.\n",
        "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25,\n",
        "#                                                     random_state=SEED)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_conv, y, test_size=0.25,\n",
        "                                                    random_state=SEED)\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "y = keras.utils.to_categorical(y, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_WwxwrreRlF6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PCA"
      ]
    },
    {
      "metadata": {
        "id": "RZBYb0vkRnSi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# PCA_DIM = 150\n",
        "# pca = PCA(n_components=PCA_DIM)\n",
        "# # Do PCA with all the data\n",
        "# pca.fit(x)\n",
        "# x_pca = pca.transform(x)\n",
        "# x_pca_train = pca.transform(x_train)\n",
        "# x_pca_test = pca.transform(x_test)\n",
        "# print(x_pca_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N6fMr0T_KupS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "uoqVOxTVKxH7",
        "colab_type": "code",
        "outputId": "b1ce3bce-5186-4fe1-8bb3-2bc0893beef5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3434
        }
      },
      "cell_type": "code",
      "source": [
        "# Build neural network model. For now, 1 hidden layer.\n",
        "# Input has a neuron for each PCA dimension, hidden layer\n",
        "# has half the neurons of the input, and the output is \n",
        "# our predictor.\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='acc', patience=3)\n",
        "\n",
        "# model = keras.Sequential([\n",
        "#    keras.layers.Dense(PCA_DIM, input_shape=(PCA_DIM,), activation=tf.nn.relu),\n",
        "#    keras.layers.Dense(PCA_DIM, activation=tf.nn.relu),\n",
        "#    keras.layers.Dense(PCA_DIM*2/3, activation=tf.nn.relu),\n",
        "#    keras.layers.Dense(PCA_DIM/3, activation=tf.nn.relu),\n",
        "#    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "# ])\n",
        "\n",
        "# model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "# model.fit(x_pca_train, y_train, epochs=100, callbacks=[early_stop])\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(4, 4),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(128, (4, 4), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              #optimizer=tf.train.AdadeltaOptimizer(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_conv, y, epochs=100, batch_size=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 13s 224us/step - loss: 0.7102 - acc: 0.7846\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.1626 - acc: 0.9520\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.1076 - acc: 0.9675\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0821 - acc: 0.9759\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0644 - acc: 0.9805\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0586 - acc: 0.9828\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0493 - acc: 0.9854\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0429 - acc: 0.9862\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0400 - acc: 0.9877\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0353 - acc: 0.9889\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.0320 - acc: 0.9901\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0294 - acc: 0.9908\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0261 - acc: 0.9917\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0241 - acc: 0.9922\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0239 - acc: 0.9922\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0231 - acc: 0.9925\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 12s 196us/step - loss: 0.0217 - acc: 0.9927\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0195 - acc: 0.9938\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0188 - acc: 0.9939\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0169 - acc: 0.9940\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0165 - acc: 0.9945\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0158 - acc: 0.9945\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0146 - acc: 0.9951\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0136 - acc: 0.9956\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0132 - acc: 0.9956\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0124 - acc: 0.9960\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0123 - acc: 0.9960\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0119 - acc: 0.9960\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0108 - acc: 0.9966\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0112 - acc: 0.9964\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0096 - acc: 0.9969\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0101 - acc: 0.9965\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0089 - acc: 0.9970\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0084 - acc: 0.9972\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0086 - acc: 0.9971\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0075 - acc: 0.9974\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0077 - acc: 0.9974\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0080 - acc: 0.9976\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0077 - acc: 0.9973\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0070 - acc: 0.9978\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0070 - acc: 0.9978\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0057 - acc: 0.9982\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0060 - acc: 0.9979\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0060 - acc: 0.9981\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0066 - acc: 0.9979\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0059 - acc: 0.9982\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0058 - acc: 0.9983\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0054 - acc: 0.9982\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0065 - acc: 0.9978\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0056 - acc: 0.9981\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0053 - acc: 0.9983\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0054 - acc: 0.9982\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0052 - acc: 0.9984\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0043 - acc: 0.9986\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0044 - acc: 0.9985\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0047 - acc: 0.9983\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0044 - acc: 0.9988\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0046 - acc: 0.9987\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0046 - acc: 0.9985\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0044 - acc: 0.9985\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0039 - acc: 0.9987\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0041 - acc: 0.9987\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0040 - acc: 0.9988\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0037 - acc: 0.9988\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0038 - acc: 0.9988\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0033 - acc: 0.9990\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0037 - acc: 0.9989\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0037 - acc: 0.9990\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0039 - acc: 0.9986\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0032 - acc: 0.9991\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0040 - acc: 0.9987\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0033 - acc: 0.9990\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0033 - acc: 0.9990\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0032 - acc: 0.9990\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0036 - acc: 0.9988\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0031 - acc: 0.9990\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0032 - acc: 0.9991\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0030 - acc: 0.9992\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0026 - acc: 0.9993\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0036 - acc: 0.9989\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0031 - acc: 0.9990\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0030 - acc: 0.9991\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0029 - acc: 0.9991\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0027 - acc: 0.9991\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0027 - acc: 0.9991\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0030 - acc: 0.9991\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0029 - acc: 0.9992\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0025 - acc: 0.9992\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0025 - acc: 0.9993\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.0029 - acc: 0.9991\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0026 - acc: 0.9991\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0028 - acc: 0.9991\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0026 - acc: 0.9993\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0022 - acc: 0.9994\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0028 - acc: 0.9991\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0027 - acc: 0.9993\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0024 - acc: 0.9992\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0026 - acc: 0.9992\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0020 - acc: 0.9993\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.0025 - acc: 0.9992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faec52fbe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Rbr-raJHN788",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test Neural Network, Retrain with All Data"
      ]
    },
    {
      "metadata": {
        "id": "KEPoItc6N6Cy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test_loss, test_acc = model.evaluate(x_pca_test, y_test)\n",
        "# print('Test accuracy:', test_acc)\n",
        "# 97.3 w/ PCA @ 100 features, 10 epochs\n",
        "# 97.6 w/ PCA @ 150 features, 10 epochs\n",
        "# 97.4 w/ PCA @ 150 features, 10 epochs, simple network w/ one hidden layer (mean of input/output)\n",
        "# 97.4 w/ PCA @ 150 features, 10 epochs, two hidden layers (mean, then \"4-mean\")\n",
        "# 97.4 w/ PCA @ 150 features, 10 epochs, two hidden layers, both size (PCA + 10)/2\n",
        "# 97.3 w/ PCA @ 150 features, 10 epochs, three hidden layers, all size (PCA + 10)/2\n",
        "# 97.1 w/ PCA @ 200 features, 10 epochs, two hidden layers, both size (PCA + 10)/2 \n",
        "# 97.3 w/ PCA @ 200 features, 10 epochs, three hidden layers: 0.75, 0.5, 0.25 * PCA\n",
        "# 97.2 w/ PCA @ 125 features, 14 epochs, three hidden layers: 0.75, 0.5, 0.25 * PCA\n",
        "# 97.5 w/ PCA @ 150 features, 20 epochs, three hidden layers: 0.75, 0.25, 0.25 * PCA\n",
        "# 97.4 w/ PCA @ 150 features, 21 epochs, two hidden layers: 2/3, 1/3 PCA\n",
        "# 97.2 w/ PCA @ 150 features, 16 epochs, two hidden layers @ PCA\n",
        "# 97.5 w/ PCA @ 150 features, 22 epochs, three hidden layers: PCA, 2/3, 1/3\n",
        "# 97.67 w/ PCA @ 150 features, 21 epochs, four hidden layers: PCA (specified \n",
        "#       input dimension), PCA, 2/3, 1/3\n",
        "# model.fit(x_pca, y, epochs=100, callbacks=[early_stop])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3iQjeL8HRmlg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predict, Write to File"
      ]
    },
    {
      "metadata": {
        "id": "-ukYpDQ1Rqnf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#y_pred = np.argmax(model.predict(pca.transform(df_test.values)), axis=1)\n",
        "y_pred = np.argmax(model.predict(x_final), axis=1)\n",
        "df_sample['Category'] = y_pred\n",
        "df_sample.to_csv('mnist.csv')\n",
        "files.download('mnist.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}