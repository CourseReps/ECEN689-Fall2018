{"cells":[{"metadata":{"_uuid":"9c7e0d083f78e43baf8353f953a30bc660bb0f40"},"cell_type":"markdown","source":"## Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\"\"\"Rather than use a CNN, let's use a very basic NN, and just feed it\nHue, Saturation, and Brightness for each image.\n\nReference: https://pdfs.semanticscholar.org/1f0d/0add993944b5230ff3548c6cb7b2e9954535.pdf\n\"\"\"\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nimport os\n\nimport tensorflow as tf\nimport random as rn\n# Seeding\nos.environ['PYTHONHASHSEED'] = '0'\nnp.random.seed(102)\nrn.seed(123)\ntf.set_random_seed(142)\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\nprint('Imports complete')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true,"_uuid":"f832b36b02a5680e496b879b10a71fff6a5e97ca"},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\nIN_DIR = os.path.join('..', 'input')\nIMAGES_DIR = os.path.join(IN_DIR, 'archive')\n\n# Load the training and testing files.\ntrain_df = pd.read_csv(os.path.join(IN_DIR, \"train.csv\"), index_col=0)\ntest_df = pd.read_csv(os.path.join(IN_DIR, \"sample.csv\"), index_col=0)\n\nprint('Training DGCI data:')\nprint(train_df['DGCI'].describe())\n\n# Extract training labels.\ny = train_df['DGCI'].values\n\n# Function to load an image, then compute it's hue, saturation, and brightness.\n# Calculations from https://pdfs.semanticscholar.org/1f0d/0add993944b5230ff3548c6cb7b2e9954535.pdf\ndef load_dgci_hsb(im_id, divisions=1):\n    # NOTE: Not here to claim this is efficient.\n    # Load the image.\n    im = cv2.imread(os.path.join(IMAGES_DIR, str(im_id) + '.jpg')) / 255.0\n    # plt.imshow(im)\n    # NOTE: Image should be width x height x 3\n    # Extract blue, green, red\n    # https://stackoverflow.com/questions/41500637/how-to-extract-r-g-b-values-with-numpy-into-seperate-arrays\n    b, g, r = cv2.split(im)\n    \n#     print('Image shape:')\n#     print(b.shape)\n#     print('Height increment: {}, Width increment: {}'.format(h_incr, w_incr))\n\n    # Initialize list for tracking hsb\n    area_hsb = []\n    \n    # Compute hsb for the entire area, always.\n    overall_hsb = hsb_from_bgr(b, g, r)\n    overall_dgci = get_dgci(*overall_hsb)\n    overall_dhsb = [overall_dgci, *overall_hsb]\n    area_hsb.extend(overall_dhsb)\n\n    # Break early if we aren't dividing the image up.\n    if divisions <= 1:\n        return area_hsb\n        \n    # Divide image into areas.\n    h_incr = round(b.shape[0] / divisions)\n    w_incr = round(b.shape[1] / divisions)\n    \n    # Initialize height index\n    h0 = 0\n\n    # Loop over the number of divisions\n    for j in range(divisions):\n        # Initialize width index\n        w0 = 0\n        \n        # Increment the height index.\n        h1 = h0 + h_incr\n\n        # Deal with rounding error\n        if h1 > b.shape[0]:\n            h1 = b.shape[0]\n\n        for k in range(divisions):\n            # Increment the width index\n            w1 = w0 + w_incr\n\n            # Deal with rounding error\n            if w1 > b.shape[1]:\n                w1 = b.shape[1]\n\n            # Grab area\n            b1 = b[h0:h1, w0:w1]\n            g1 = g[h0:h1, w0:w1]\n            r1 = r[h0:h1, w0:w1]\n            \n#             print('Rows: {}:{}'.format(h0, h1))\n#             print('Columns: {}:{}'.format(w0, w1))\n            \n            # Compute hsb for this area\n            this_hsb = hsb_from_bgr(b1, g1, r1)\n            this_dgci = get_dgci(*this_hsb)\n            this_dhsb = [this_dgci, *this_hsb]\n            area_hsb.extend(this_dhsb)\n\n            # Set w0 to w1 for the next iteration\n            w0 = w1\n\n        # Set h0 to h1 for the next iteration\n        h0 = h1\n    \n    # Return.\n    return area_hsb\n    \ndef hsb_from_bgr(b, g, r):\n    \"\"\"Compute hue, saturation, and brightness given matrices for blue, red, and green pixels.\"\"\"\n    # Put means in a list.\n#     print(b.shape)\n#     print(g.shape)\n#     print(r.shape)\n    b_m = np.mean(b)\n    g_m = np.mean(g)\n    r_m = np.mean(r)\n    m = [b_m, g_m, r_m]\n    \n    # Compute brightness\n    brightness = max(m)\n    \n    # Compute the range.\n    rng = brightness - min(m)\n    \n    # Compute saturation\n    sat = rng / brightness\n    \n    # Compute the hue.\n    # Alternate computation from paper: http://code.activestate.com/recipes/576919-python-rgb-and-hsv-conversion/\n    if brightness == r_m:\n        # hue = 60 * ((g_m - b_m)/rng)\n        hue = (60 * (g_m - b_m)/rng + 360) % 360 \n    elif brightness == g_m:\n        # hue = 60 * (2 + ((b_m - r_m)/rng))\n        hue = (60 * (b_m - r_m)/rng + 120) % 360\n    elif brightness == b_m:\n        # hue = 60 * (4 + ((r_m - g_m)/rng))\n        hue = (60 * (r_m - g_m)/rng + 240) % 360\n    else:\n        raise UserWarning('Something is going wrong.')   \n        \n    # If hue is < 0, add 360\n#     if hue < 0:\n#         hue = hue + 360\n    \n    return hue, sat, brightness\n\ndef get_dgci(h, s, b):\n    # https://pdfs.semanticscholar.org/1f0d/0add993944b5230ff3548c6cb7b2e9954535.pdf\n    return ((h - 60)/60 + 2 - s - b)/3\n    \n# Initialize training data.\n# Determine how many divisions we're using\nDIVISIONS = 4\n# (dgci, hue, saturation, brightness (entire image)), (dgci, h, s, b (area)), ...\nCOLUMNS = (1 * 4) + (4 * DIVISIONS**2)\n\ndef get_data(df):\n    \"\"\"Helper to get data from a given DataFrame\"\"\"\n    # Initialize.\n    x = np.zeros(shape=(df.shape[0], COLUMNS))\n    \n    # Loop to load images.\n    x_idx = 0\n    for row in df.itertuples():\n        # NOTE: THIS IS NOT VECTORIZED OR EFFICIENT.\n        dgci_hsb = load_dgci_hsb(row.Index, divisions=DIVISIONS)\n        x[x_idx, :] = dgci_hsb\n        x_idx += 1\n    \n    return x\n\nx = get_data(train_df)\n\nprint('\\nDGCI, Hue, Saturation, and Brightness data:')\nprint(pd.DataFrame(x).describe())\nprint('Data loaded.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2dadd79b3b0fde8f8123ab072fff8251392ad6ec"},"cell_type":"markdown","source":"## Visualize Hue, Saturation, and Brightness Data"},{"metadata":{"trusted":true,"_uuid":"f2820abb364964523eca94ea179d65a0bf0fbf46"},"cell_type":"code","source":"# Order is Hue, Saturation, Brightness\nfor k in range(3):\n    ax = plt.subplot(3, 1, k+1)\n    ax.hist(x[:, k+1])\n    \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa74be114bc0254aa727f4bc9e3cd333dde52f65"},"cell_type":"markdown","source":"## Visualize DGCI"},{"metadata":{"trusted":true,"_uuid":"fc94aad6ae2283ae2a041a24de72e520f470ce0e"},"cell_type":"code","source":"plt.plot(x[:, 0], y, linestyle='None', marker='.')\nplt.xlabel('Computed DGCI')\nplt.ylabel('Given DGCI')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd6613148a5b8e2a9294a7d82ce8693777144873"},"cell_type":"markdown","source":"## Normalize Data"},{"metadata":{"trusted":true,"_uuid":"dbdfaf66d6714fd96a73ec4c6fda8a305b61ceaf"},"cell_type":"code","source":"# The StandardScaler() led to smallest MSE on training data\nx_scaler = StandardScaler()\nx_norm = x_scaler.fit_transform(x)\n\ny_scaler = StandardScaler()\ny_norm = y_scaler.fit_transform(y.reshape(-1, 1))\nprint('Normalization complete.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d63fb70980879e390b8410939285c19d81bf9eea"},"cell_type":"markdown","source":"## Split Train/Val"},{"metadata":{"trusted":true,"_uuid":"3496052ca40520371161ba02fbc6a58ff6aba15d"},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_norm, y_norm, test_size=0.25)\nprint('Data split for training/validation')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e938c4f5e5c34eff612be76b49ac585e2099b1ea"},"cell_type":"markdown","source":"## Initialize Neural Network"},{"metadata":{"trusted":true,"_uuid":"560ecf6a822e86413e4d554b49e237ccdcaf1f34"},"cell_type":"code","source":"###################################################################\n# ROBUST SCALER\n# For the following, network fixed at 64, 64, 1, and patience @ 10\n# RMSPropOptimizer, epochs: 28, mse: 0.010\n# AdaDelta(), epochs: 46, mse: 0.011\n\n##################################################################\n# MIN MAX SCALER\n# For the following, network fixed at 64, 64, 1, and patience @ 10\n# RMSPropOptimizer: epochs 64, mse: 0.0076\n# AdaDelta(), epochs 64, mse: 0.0081\n\n#################################################################\n# STANDARD SCALER\n# For the following, network fixed at 64, 64, 1, and patience @ 10\n# RMSPropOptimizer: epochs 74, mse: 0.0074\n# AdaDelta(), epochs 33, mse: 0.0077\n\n################################################################\n# STANDARD SCALER\n# RMSPROPOPTMIZER\n# PATIENCE: 10\n# 0.25 dropout: epochs 71, mse 0.0098\n\n################################################################\n# STANDARD SCALER\n# RMSPROPOPTIMIZER\n# PATIENCE: 10\n# 0.25 DROPOUT BETWEEN LAYERS\n#\n# 64, 64: mse: 0.0105, val_mse: 0.0099\n# 128, 128: mse: 0.0094, val_mse: 0.0103\n# 128, 64: mse: 0.0095, val_mse: 0.0072\n\nmodel = keras.Sequential()\nmodel.add(Dense(256, activation='relu', input_shape=(x_norm.shape[1],)))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(1))\n\nearly_stop = keras.callbacks.EarlyStopping(monitor='mean_squared_error', patience=10)\n\noptimizer = tf.train.RMSPropOptimizer(0.001)\n# optimizer = keras.optimizers.Adadelta()\nmodel.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n\nmodel.fit(x_train, y_train, epochs=200, callbacks=[early_stop], validation_data=(x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55edf7b6de4b7ddd448f3d8a52ca840d7a181eda"},"cell_type":"markdown","source":"## Compute Training and Testing MSE"},{"metadata":{"trusted":true,"_uuid":"79bc95928e4e88e420efeceb34051e73a789fba1"},"cell_type":"code","source":"# Perform predictions, then rescale.\n\ny_tr_pred = model.predict(x_train)\ny_te_pred = model.predict(x_test)\ny_tr_mse = mean_squared_error(y_scaler.inverse_transform(y_train.reshape(-1, 1)), y_scaler.inverse_transform(y_tr_pred.reshape(-1, 1)))\ny_te_mse = mean_squared_error(y_scaler.inverse_transform(y_test.reshape(-1, 1)), y_scaler.inverse_transform(y_te_pred.reshape(-1, 1)))\nprint('\\nFinal Training MSE: {:.4f}'.format(y_tr_mse))\nprint('Final Testing MSE: {:.4f}'.format(y_te_mse))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49eb34441f0141b9ae20da0e207a0f71bb4d0785"},"cell_type":"markdown","source":"## Train with Full Data Set"},{"metadata":{"trusted":true,"_uuid":"52aec23f6fadd043820eaa4635647286c50d2c3d"},"cell_type":"code","source":"# Use reduced patience to avoid over-fitting\nearly_stop = keras.callbacks.EarlyStopping(monitor='mean_squared_error', patience=5)\nmodel.fit(x_norm, y_norm, epochs=200, callbacks=[early_stop])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20b5d310450fa3d1e5dc2f4f662e094ea67c4447"},"cell_type":"markdown","source":"## Testing Data: Load, HSB, Scaling"},{"metadata":{"trusted":true,"_uuid":"16da058f9ae606808ba06a18bdab3c231e548a34"},"cell_type":"code","source":"# Initialize testing data.\nx_t = get_data(test_df)\n\n# Normalize\nx_norm_test = x_scaler.transform(x_t)\n\nprint('Testing data loaded and normalized.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4f3b7615f29e6a89ea85e3aed4c542d5708c8a3"},"cell_type":"markdown","source":"## Predictions"},{"metadata":{"trusted":true,"_uuid":"ce4b2dfff345469c5436e90eea48abd60531f148"},"cell_type":"code","source":"y_test = model.predict(x_norm_test)\ntest_df['DGCI'] = y_scaler.inverse_transform(y_test.reshape(-1, 1))\nprint(test_df.head())\nprint(test_df.describe())\n#test_df.to_csv('output.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6ed3f6c7c61a773dfa79717cb8705c8327f4f10"},"cell_type":"code","source":"# Linear regression\nlin_reg = LinearRegression()\nlin_reg.fit(x_norm, y_norm)\ny_pred = lin_reg.predict(x_norm)\nprint('Linear Regression:')\nprint('Training MSE {:.4f}'.format(mean_squared_error(y_scaler.inverse_transform(y_norm.reshape(-1, 1)),\n                                                      y_scaler.inverse_transform(y_pred.reshape(-1, 1)))))\n\ny_test = lin_reg.predict(x_norm_test)\ntest_df['DGCI'] = y_scaler.inverse_transform(y_test.reshape(-1, 1))\nprint(test_df.head())\nprint(test_df.describe())\ntest_df.to_csv('output_lin.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}