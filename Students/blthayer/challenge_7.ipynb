{"cells":[{"metadata":{"_uuid":"4c32e6d14d5a8e768e8f8b62f0b145535157ccf1"},"cell_type":"markdown","source":"## Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\"\"\"ECEN 689 Challenge 7 - TAMU DGCI\n\nhttps://www.kaggle.com/c/tamu-dgci\n\nThis kernel already has the data needed in it.\n\"\"\"\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport random as rn\nfrom skimage.transform import resize\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nimport cv2\nimport colorsys\n\n# Seeding\nos.environ['PYTHONHASHSEED'] = '0'\nnp.random.seed(102)\nrn.seed(123)\ntf.set_random_seed(142)\n\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n\nprint('Imports complete')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"542bd37295948aec1851ac3dd1a86c36cfb21c43"},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true,"_uuid":"09910248604b6c4402f755d3477beff29f42d757"},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\nIN_DIR = os.path.join('..', 'input')\nIMAGES_DIR = os.path.join(IN_DIR, 'archive')\n# print(os.listdir(IN_DIR))\n\n# By loading the first file, we can see that the images are (300, 400, 3)\n# im = plt.imread(os.path.join(IMAGES_DIR, os.listdir(IMAGES_DIR)[0]))\n# plt.imshow(im)\n# print(im.shape)\n# print(np.max(im))\n# print(np.min(im))\nIMG_ROWS = 224\nIMG_COLS = 224\nIMG_DEPTH = 3\nIMG_SHAPE = (IMG_ROWS, IMG_COLS, IMG_DEPTH)\n\nif keras.backend.image_data_format() == 'channels_first':\n    raise UserWarning('I did not bother to implement the channels_first shape.')\n    # print('channels first')\n    input_shape = ()\nelse:\n    # print('data first')\n    data_format = 'channels_last'\n\n# Load the training and testing files.\ntrain_df = pd.read_csv(os.path.join(IN_DIR, \"train.csv\"), index_col=0)\ntest_df = pd.read_csv(os.path.join(IN_DIR, \"sample.csv\"), index_col=0)\n\n# Compute the number of negative samples.\nprint('Out of {} training samples, {} have a DGCI < 0.'.format(train_df.shape[0],\n                                                               np.count_nonzero(train_df['DGCI'].values < 0)))\n\n# # Translate DGCI to [0, 1] interval\n# mms = MinMaxScaler(feature_range=(0, 1))\n# mms.fit(train_df['DGCI'].values.reshape(-1, 1))\n# y_train = mms.transform(train_df['DGCI'].values.reshape(-1, 1)).ravel()\ny_train = train_df['DGCI'].values.ravel()\n\n# Get listing of all the files.\nall_files = os.listdir(IMAGES_DIR)\n\n# Initialize arrays to hold images.\nx_train = np.zeros(shape=(train_df.shape[0], *IMG_SHAPE))\nx_test = np.zeros(shape=(test_df.shape[0], *IMG_SHAPE))\nid_test = []\n\n# Function for loading and reshaping and image.\ndef load_reshape(im_id):\n    temp_im = cv2.imread(os.path.join(IMAGES_DIR, str(im_id) + '.jpg')) #/ 255.0\n    # Get hsb\n    # im_hsb = cv2.cvtColor(temp_im, cv2.COLOR_BGR2HSV)\n    \n    im = resize(temp_im/255.0, IMG_SHAPE, mode='reflect')\n    return im\n\n# Loop over training data.\nx_idx = 0\nfor row in train_df.itertuples():\n    im = load_reshape(row.Index)\n    x_train[x_idx, :, :, :] = im\n    x_idx += 1\n\n# Create weights. <10% of samples have a DGCI < 1, so\n# we'll double the weight of those samples.\nsample_weights = np.ones(train_df.shape[0])\nsample_weights[train_df['DGCI'].values < 0] = 2\n\n# DGCI actually goes from 0 to 1\n# https://pdfs.semanticscholar.org/1f0d/0add993944b5230ff3548c6cb7b2e9954535.pdf\n# https://scholarworks.uark.edu/cgi/viewcontent.cgi?referer=https://www.google.com/&httpsredir=1&article=2455&context=etd\n# AFTER LOOKING AT THE IMAGES, IT'S A BAD IDEA TO RUN THE CODE BELOW.\n# print('IMPORTANT NOTE:')\n# print('Negative DGCI values have been multiplied by -1. DGCI should be on [0,1] interval.')\n# train_df[train_df['DGCI'] < 0] *= -1\n\n# Loop over testing data.\nx_idx = 0\nfor row in test_df.itertuples():\n    im = load_reshape(row.Index)\n    x_test[x_idx, :, :, :] = im\n    x_idx += 1\n        \nprint('All images loaded.')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b2a72bf51bb9d3d83dc3b51c39fcc2ac0b08751"},"cell_type":"markdown","source":"## Examine Training Data"},{"metadata":{"trusted":true,"_uuid":"d6d6287fdd8092e46451463b875e025368a771b5"},"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)\nprint(np.max(x_train))\nprint(np.min(x_train))\n# Make sure things are working.\nfor k in range(4):\n    rand_ind = np.random.randint(low=0, high=x_train.shape[0])\n    ax = plt.subplot(2, 2, k+1)\n    ax.imshow(np.reshape(x_train[rand_ind, :, :, :], IMG_SHAPE))\n    ax.set_title('Image {}. DGCI: {:.2f}'.format(train_df.index[rand_ind], train_df.iloc[rand_ind]['DGCI']))\n    \nplt.tight_layout()\n\nprint('DGCI stats:')\nprint(train_df['DGCI'].describe())\n\nprint('Scaled DGCI stats:')\nprint(pd.Series(y_train).describe())\n#plt.imshow(np.reshape(x_train[5, :, :, :], IMG_SHAPE))\n#plt.imshow(np.reshape(x_test[5, :, :, :], IMG_SHAPE))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"009939128e5af7ffa9fbaa2819f8f28cb302f56c"},"cell_type":"markdown","source":"## Look at Negative DGCI in the Training Data"},{"metadata":{"trusted":true,"_uuid":"c3590125b3354d34c065a0c0691e834f932287a8"},"cell_type":"code","source":"ind = np.arange(train_df.shape[0])\nneg_indices = ind[train_df['DGCI'].values < 0]\nfor k in range(4):\n    rand_ind = np.random.choice(neg_indices)\n    ax = plt.subplot(2, 2, k+1)\n    ax.imshow(np.reshape(x_train[rand_ind, :, :, :], IMG_SHAPE))\n    ax.set_title('Image {}. DGCI: {:.2f}'.format(train_df.index[rand_ind], train_df.iloc[rand_ind]['DGCI']))\n    \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c93a51c93a954fbc69ae8222181c43f990d788b1"},"cell_type":"markdown","source":"## Look at Testing Data"},{"metadata":{"trusted":true,"_uuid":"189566526a05ccc34a6e37b4855f676a3d414c08"},"cell_type":"code","source":"for k in range(4):\n    rand_ind = np.random.randint(low=0, high=x_test.shape[0])\n    ax = plt.subplot(2, 2, k+1)\n    ax.imshow(np.reshape(x_test[rand_ind, :, :, :], IMG_SHAPE))\n    ax.set_title('Image {}'.format(train_df.index[rand_ind]))\n    \nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93114e89c0c18f74654444764480809fe6d12563"},"cell_type":"code","source":"# # Scale test data.\n# x_scaler = StandardScaler()\n# x_norm_train = x_scaler.fit_transform(x_train)\n# x_norm_test = x_scaler.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e44211c55faa77145b7ea99ec3f518131c8b4390"},"cell_type":"markdown","source":"## Setup CNN"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Based on my interpretation of: https://arxiv.org/pdf/1409.1556.pdf\n# To start, we ran with configuration A\n# TODO: try configuration C (adding 1x1 convolution)\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size=3, strides=1, activation='relu', input_shape=IMG_SHAPE, padding='same', kernel_regularizer=keras.regularizers.l2(5e-4), data_format=data_format))\nmodel.add(AveragePooling2D(pool_size=2, strides=2))\nmodel.add(Conv2D(128, kernel_size=3, strides=1, activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(5e-4), data_format=data_format))\nmodel.add(AveragePooling2D(pool_size=2, strides=2))\nmodel.add(Conv2D(256, kernel_size=3, strides=1, activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(5e-4), data_format=data_format))\nmodel.add(Conv2D(256, kernel_size=3, strides=1, activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(5e-4), data_format=data_format))\nmodel.add(AveragePooling2D(pool_size=2, strides=2))\nmodel.add(Conv2D(512, kernel_size=3, strides=1, activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(5e-4), data_format=data_format))\nmodel.add(Conv2D(512, kernel_size=3, strides=1, activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(5e-4), data_format=data_format))\nmodel.add(AveragePooling2D(pool_size=2, strides=2))\nmodel.add(Conv2D(512, kernel_size=3, strides=1, activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(5e-4), data_format=data_format))\nmodel.add(Conv2D(512, kernel_size=3, strides=1, activation='relu', padding='same', kernel_regularizer=keras.regularizers.l2(5e-4), data_format=data_format))\nmodel.add(Flatten())\n# This is where we deviate from the paper - they used two Dense @ 4096 into a 1000-way softmax.\n# Since we're doing more of a regression task, we'll use smaller layers, and of course end\n# with a single node.\nmodel.add(Dense(1024, activation='relu', kernel_regularizer=keras.regularizers.l2(5e-4)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1024, activation='relu', kernel_regularizer=keras.regularizers.l2(5e-4)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\n\n\n# optimizer = tf.train.RMSPropOptimizer(0.001)\noptimizer = keras.optimizers.SGD(0.01, momentum=0.9)\n# optimizer = keras.optimizers.Adadelta()\nmodel.compile(loss=keras.losses.mean_squared_error, optimizer=optimizer, metrics=['mse'], weighted_metrics=['mse'])\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f7f8ea6afaadb353930c5e0ca60e86a0779a6cb"},"cell_type":"markdown","source":"## Train CNN"},{"metadata":{"trusted":true,"_uuid":"c5cf2994c822127505204d86ce7cb1538c8a1e8e"},"cell_type":"code","source":"# Use ImageDataGenerator to increase the effective size of our dataset.\n# Was tracking some metrics here, but was using bad data...\ndg = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True, width_shift_range=0.5, height_shift_range=0.5, fill_mode='wrap',\n                                                 rotation_range=180, shear_range=180, data_format=data_format)\ndg.fit(x_train)\n\n# Initial training\nprint('Training with rate at 0.01')\nearly_stop = keras.callbacks.EarlyStopping(monitor='weighted_mean_squared_error', patience=10)\nbatch_size = 32\nmodel.fit_generator(dg.flow(x_train, y_train, batch_size=batch_size, sample_weight=sample_weights),\n                    epochs=68, verbose=2, steps_per_epoch=(x_train.shape[0] / batch_size)) #, callbacks=[early_stop])\n\n# # Don't really see improvement for the reduced learning rates.\n# # Recompile with smaller learning rate.\n# print('\\nTraining with rate at 0.001')\n# optimizer = keras.optimizers.SGD(0.001, momentum=0.9)\n# model.compile(loss=keras.losses.mean_squared_error, optimizer=optimizer, metrics=['mse'])\n# model.fit(x_train, y_train, epochs=200, verbose=2, batch_size=128, sample_weight=sample_weights, callbacks=[early_stop])\n\n# # Recompile with smaller learning rate.\n# print('\\nTraining with rate at 0.0001')\n# optimizer = keras.optimizers.SGD(0.0001, momentum=0.9)\n# model.compile(loss=keras.losses.mean_squared_error, optimizer=optimizer, metrics=['mse'])\n# model.fit(x_train, y_train, epochs=200, verbose=2, batch_size=128, sample_weight=sample_weights, callbacks=[early_stop])\n\n# swap to average pooling:\n# mean_squared_error: 0.0406 - weighted_mean_squared_error: 0.0682","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1444fc277b348c10c307c47c26635eb01bb4438c"},"cell_type":"markdown","source":"## Make Predictions, Write to File"},{"metadata":{"trusted":true,"_uuid":"9468e2da5fec651f100ad73d842de515404ad496"},"cell_type":"code","source":"# Test.\n# y_test = mms.inverse_transform(model.predict(x_test))\ny_test = model.predict(x_test)\ntest_df['DGCI'] = y_test.ravel()\nprint(test_df.head())\nprint(test_df.describe())\n# Write to file.\ntest_df.to_csv('output.csv')\n\nyt = model.predict(x_train)\nprint(pd.Series(yt.ravel()).describe())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5dbc626053682791fe81b402b977f1b9e47f1af"},"cell_type":"markdown","source":"## Plot Predictions"},{"metadata":{"trusted":true,"_uuid":"a6cc6bdae127e849ae0e6930b6171b6dc77f1ac4"},"cell_type":"code","source":"for k in range(4):\n    rand_ind = np.random.randint(low=0, high=x_test.shape[0])\n    ax = plt.subplot(2, 2, k+1)\n    ax.imshow(np.reshape(x_test[rand_ind, :, :, :], IMG_SHAPE))\n    ax.set_title('Image {}. DGCI: {:.2f}'.format(test_df.index[rand_ind], test_df.iloc[rand_ind]['DGCI']))\n    \nplt.tight_layout()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}