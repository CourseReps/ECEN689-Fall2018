# Introduction to Feature Engineering
by Anirudh Shaktawat and Kanchan Satpute

Nowadays, Everybody thinks that the better the features they will choose and prepare, the better the results they will achieve for their machine learning model! This is a true statement but at the same time it is a misleading statement. In reality, the results in a machine learning model depend on various factors (as shown in the image).

![Pic1](https://github.com/anirudh2312/deep-learning/blob/master/images/Picture1.png)

Then the question is "Why Feature Engineering" !The importance of Feature Engineering is evident in the three statements which are:

#### Better feature means better flexibility:
Better features lead to less complex models, Faster to run, Easier to understand and Easier to maintain.

#### Better feature means simpler models:
Even if you have chosen wrong parameters (not the most optimized ones) for your machine learning model, you may still get good results if you have better features. You do not need to work as hard to pick the right models and the most optimized parameters. 

#### Better feature means better results:
In fact, Xavier Conort (current grandmaster and former 1st ranker on Kaggle) once said, 'The algorithms we used are very standard for Kagglers. We spent most of our efforts in Feature Engineering', when asked in an interview when he won one of the toughest known challenges on Kaggle.

From the above arguments, it is clear that Feature Engineering is indeed important for success in machine learning, most of the times. Now, the question arises that "What is Feature Engineering"! Different people interpret this term in different ways:
1. Some think that extracting out features from raw data by reducing the dimensionality of observations into a much smaller set, is feature engineering. 
2. Others think that the process of scoring and ranking the features and selecting the best subset of features, is feature engineering
3. Most of the people think that manually creating new features using the given raw data, is feature engineering


### Feature Engineering:
Feature Engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on resulting data. 
![Pic2](https://github.com/anirudh2312/deep-learning/blob/master/images/Picture2.png)
Feature engineering is a broad topic and there are many subproblems that come under feature engineering, like Feature Extraction, Feature Selection and Feature Creation.

#### Feature Extraction: ‘automatic construction of new features from raw data’
Some observations, in their raw state are far too voluminous to be modelled by predictive modelling algorithms directly. Common examples include: image, audio, video, textual data. 
![Pic3](https://github.com/anirudh2312/deep-learning/blob/master/images/Capture.PNG)



